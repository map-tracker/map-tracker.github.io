<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MapTracker: Tracking with Strided Memory Fusion for Consistent Vector HD Mapping.">
  <meta name="keywords" content="Vector HD mapping, Autonomous driving">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MapTracker: Tracking with Strided Memory Fusion for Consistent Vector HD Mapping</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icons8-autonomous-car-64.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MapTracker: Tracking with Strided Memory Fusion for Consistent Vector HD Mapping</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jcchen.me/">Jiacheng Chen</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://ivenwu.com/">Yuefan Wu</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://christinatan0704.github.io/mysite/">Jiaqi Tan</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.sfu.ca/~hangma/">Hang Ma</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yasu-furukawa.github.io/">Yasutaka Furukawa</a><sup>1,2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Simon Fraser University</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">


    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper presents a vector HD-mapping algorithm that formulates the mapping as a tracking 
            task and uses a history of memory latents to ensure consistent reconstructions over time.
          </p>
          <p>
            Our method, <i>MapTracker</i>, accumulates a sensor stream into memory buffers of two latent 
            representations: 1) Raster latents in the bird's-eye-view (BEV) space and 2) Vector latents over 
            the road elements (i.e., pedestrian-crossings, lane-dividers, and road-boundaries).
            The approach borrows the query propagation paradigm from the tracking literature that explicitly associates tracked road elements from the previous frame to the current, while fusing a subset of memory latents selected with distance strides to further enhance temporal consistency.A vector latent is decoded to reconstruct the geometry of a road element. 
          </p>
          <p>
            The paper further makes benchmark contributions by 1) Improving processing code for existing datasets 
            to produce consistent ground truth with temporal alignments and 2) Augmenting existing mAP metrics with consistency checks. MapTracker significantly outperforms existing methods on both nuScenes and Agroverse2 datasets by over 8% and 19% on the conventional and the new consistency-aware metrics, respectively.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->



    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->


    

  </div>
</section>


<section class="section">

  <!-- <div class="column is-full-width"></div> -->
  
  <div class="container is-max-desktop">

    <div class="columns">
      <h2 class="title is-2"style="text-align: left;">Reconstruction results</h2>
    </div>

    <div class="columns is-centered" style="display: flex; align-items: center; height: 100%;">
      <!-- Visual Effects. -->
      <div class="column">
        <div class="columns is-centered" >
          <div class="column content" style="display: flex; justify-content: center; ">
            <video id="matting-video" controls playsinline height="100%" width="100%">
              <source src="./static/videos/93_results.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>

    </div>

    <div class="columns is-centered" style="display: flex; align-items: center; height: 100%;">
      <!-- Visual Effects. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="matting-video" controls playsinline height="100%" width="100%">
              <source src="./static/videos/636_results.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>


    <div class="columns is-centered" style="display: flex; align-items: center; height: 100%;">
      <!-- Visual Effects. -->
      <div class="column">
        <!-- <h2 class="title is-3">Input Video</h2> -->
        <div class="columns is-centered">
          <div class="column content">
            <video id="matting-video" controls playsinline height="100%" width="100%">
              <source src="./static/videos/av2_214_results.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>


    <!-- <div class="columns is-centered" style="display: flex; align-items: center; height: 100%;">
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="matting-video" controls playsinline height="100%" width="100%">
              <source src="./static/videos/merged.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div> -->

    <!-- SPLIT LINE -->



    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Random selected samples</h2>
      

        <!-- Interpolating. -->
        <h3 class="title is-3">nuScenes</h3>
        <!-- <div class="columns is-vcentered interpolation-panel"> -->
          <video id="nusc-random-video" controls playsinline autoplay height="100%" width="100%">
            <source src="./static/videos/nusc_random.mp4"
                    type="video/mp4">
          </video>
        <br/>
        <br/>

        <h3 class="title is-3">Agroverse2</h3>
        <video id="av2-random-video" controls playsinline autoplay height="100%" width="100%">
          <source src="./static/videos/random_av2.mp4"
                  type="video/mp4">
        </video>

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
             The website template is borrowed from <a
              href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
